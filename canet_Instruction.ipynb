{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "canet",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92cYIeQF0bAQ",
        "colab_type": "text"
      },
      "source": [
        "# Segmentation of Indian Traffic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTtIHDSf0bBY",
        "colab_type": "text"
      },
      "source": [
        "# Task 3: Training CANet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM6PTaqo0bBY",
        "colab_type": "code",
        "outputId": "d6d44dc2-2471-4368-ecad-204a26be17ae",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "# tf.compat.v1.enable_eager_execution()\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import UpSampling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.layers import Multiply\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "K.set_image_data_format('channels_last')\n",
        "K.set_learning_phase(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "D:\\installed\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0DIdIxO0bBb",
        "colab_type": "text"
      },
      "source": [
        "* as a part of this assignment we will be implementing the architecture based on this paper https://arxiv.org/pdf/2002.12041.pdf\n",
        "* We will be using the custom layers concept that we used in seq-seq assignment\n",
        "* You can devide the whole architecture can be devided into two parts\n",
        "    1. Encoder\n",
        "    2. Decoder\n",
        "    <img src='https://i.imgur.com/prH3Mno.png' width=\"600\">\n",
        "* Encoder:\n",
        "    * The first step of the encoder is to create the channel maps [$C_1$, $C_2$, $C_3$, $C_4$]\n",
        "    * $C_1$ width and heigths are 4x times less than the original image\n",
        "    * $C_2$ width and heigths are 8x times less than the original image\n",
        "    * $C_3$ width and heigths are 8x times less than the original image\n",
        "    * $C_4$ width and heigths are 8x times less than the original image\n",
        "    * <i>you can reduce the dimensions by using stride parameter</i>.\n",
        "    * [$C_1$, $C_2$, $C_3$, $C_4$] are formed by applying a \"conv block\" followed by $k$ number of \"identity block\". i.e the $C_k$ feature map will single \"conv block\" followed by $k$ number of \"identity blocks\".\n",
        "    <table>\n",
        "    <tr><td><img src=\"https://i.imgur.com/R8Gdypo.png\" width=\"300\"></td>\n",
        "        <td><img src=\"https://i.imgur.com/KNunjQK.png\" width=\"250\"></td></tr>\n",
        "    </table>\n",
        "    * <strong>The conv block and identity block of $C_1$</strong>: the number filters in the covolutional layers will be $[4,4,8]$ and the number of filters in the parallel conv layer will also be $8$.\n",
        "    * <strong>The conv block and identity block of $C_2$</strong>: the number filters in the covolutional layers will be $[8,8,16]$ and the number of filters in the parallel conv layer will also be $16$.\n",
        "    * <strong>The conv block and identity block of $C_3$</strong>: the number filters in the covolutional layers will be $[16,16,32]$ and the number of filters in the parallel conv layer will also be $32$.\n",
        "    * <strong>The conv block and identity block of $C_4$</strong>: the number filters in the covolutional layers will be $[32,32,64]$ and the number of filters in the parallel conv layer will also be $64$.\n",
        "    * Here $\\oplus$ represents the elementwise sum\n",
        "    <br>\n",
        "    \n",
        "    <font color=\"red\">NOTE: these filters are of your choice, you can explore more options also</font>\n",
        "    \n",
        "    * Example: if your image is of size $(512, 512, 3)$\n",
        "        * the output after $C_1$ will be $128*128*8$\n",
        "        * the output after $C_2$ will be $64*64*16$\n",
        "        * the output after $C_3$ will be $64*64*32$\n",
        "        * the output after $C_4$ will be $64*64*64$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNP8W_o90bBg",
        "colab_type": "text"
      },
      "source": [
        "* The output of the $C_4$ will be passed to $\\text{Chained Context Aggregation Module (CAM)}$\n",
        "<img src='https://i.imgur.com/Bu63AAA.png' width=\"400\">\n",
        "* The CAM module will have two operations names Context flow and Global flow\n",
        "* <strong>The Global flow</strong>: \n",
        "    * as shown in the above figure first we willl apply  <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/GlobalAveragePooling2D\">global avg pooling</a> which results in (#, 1, 1, number_of_filters) then applying <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization?version=nightly\">BN</a>, <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU\">RELU</a>, $1*1 \\text{ Conv}$ layer sequentially which results a matrix (#, 1, 1, number_of_filters). Finally apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> / <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\">conv2d transpose</a> to make the output same as the input dimensions (#, input_height, input_width, number_of_filters)\n",
        "    * If you use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> then use bilinear pooling as interpolation technique\n",
        "* <strong>The Context flow</strong>: \n",
        "    * as shown in the above figure (c) the context flow will get inputs from two modules `a. C4` `b. From the above flow` \n",
        "    * We will be <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Concatenate\">concatinating</a> the both inputs on the last axis.\n",
        "    * After the concatination we will be applying <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D\"> Average pooling </a> which reduces the size of feature map by $N\\times$ times\n",
        "    * In the paper it was mentioned that to apply a group convolutions, but for the assignment we will be applying the simple conv layers with kernel size $(3*3)$\n",
        "    * We are skipping the channel shuffling \n",
        "    * similarly we will be applying a simple conv layers with kernel size $(3*3)$ consider this output is X\n",
        "    * later we will get the Y=(X $\\otimes \\sigma((1\\times1)conv(relu((1\\times1)conv(X))))) \\oplus X$, here $\\oplus$ is elementwise addition and $\\otimes$ is elementwise multiplication\n",
        "    * Finally apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> / <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2DTranspose\">conv2d transpose</a> to make the output same as the input dimensions (#, input_height, input_width, number_of_filters)\n",
        "    * If you use <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> then use bilinear pooling as interpolation technique\n",
        "\n",
        "NOTE: here N times reduction and N time increments makes the input and out shape same, you can explore with the N values, you can choose N = 2 or 4\n",
        "\n",
        "* Example with N=2:\n",
        "    * Assume the C4 is of shape (64,64,64) then the shape of GF will be (64,64,32)\n",
        "    * Assume the C4 is of shape (64,64,64) and the shape of GF is (64,64,32) then the shape of CF1 will be (64,64,32)\n",
        "    * Assume the C4 is of shape (64,64,64) and the shape of CF1 is (64,64,32) then the shape of CF2 will be (64,64,32)\n",
        "    * Assume the C4 is of shape (64,64,64) and the shape of CF2 is (64,64,32) then the shape of CF3 will be (64,64,32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZyxvYZp0bBm",
        "colab_type": "text"
      },
      "source": [
        "* As shown in the above architecture we will be having 4 context flows\n",
        "* if you have implemented correctly all the shapes of Global Flow, and 3 context flows will have the same dimension\n",
        "* the output of these 4 modules will be <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Add\">added</a> to get the same output matrix\n",
        "<img src='https://i.imgur.com/Bu63AAA.png' width=\"400\">\n",
        " * The output of after the sum, will be sent to the <strong>Feature selection module $FSM$</strong>\n",
        " \n",
        "* Example:\n",
        "    * if the shapes of GF, CF1, CF2, CF3 are (64,64,32), (64,64,32), (64,64,32), (64,64,32), (64,64,32) respectivly then after the sum we will be getting (64,64,32), which will be passed to the next module.\n",
        " \n",
        "<strong>Feature selection module</strong>:\n",
        "\n",
        "* As part of the FSM we will be applying a conv layer (3,3) with the padding=\"same\" so that the output and input will have same shapes\n",
        "* Let call the output as X\n",
        "* Pass the X to global pooling which results the matrix (#, 1, 1, number_of_channels)\n",
        "* Apply $1*1$ conv layer, after the pooling\n",
        "* the output of the $1*1$ conv layer will be passed to the Batch normalization layer, followed by Sigmoid activation function.\n",
        "* we will be having the output matrix of shape (#, 1, 1, number_of_channels) lets call it 'Y'\n",
        "* <strong>we can interpret this as attention mechanisum, i.e for each channel we will having a weight</strong>\n",
        "* the dimension of X (#, w, h, k) and output above steps Y is (#, 1, 1, k) i.e we need to multiply each channel of X will be <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Multiply\">multiplied</a> with corresponding channel of Y\n",
        "* After creating the weighted channel map we will be doing upsampling such that it will double the height and width.\n",
        "* apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> with bilinear pooling as interpolation technique\n",
        "\n",
        "* <font color=\"red\">Example</font>:\n",
        "    * Assume the matrix shape of the input is (64,64,32) then after upsampling it will be (128,128,32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xoqx8w50bBp",
        "colab_type": "text"
      },
      "source": [
        "* <b>Adapted Global Convolutional Network (AGCN)</b>:\n",
        "    <img src=\"https://i.imgur.com/QNB8RmV.png\" width=\"300\">\n",
        "    \n",
        "    * AGCN will get the input from the output of the \"conv block\" of $C_1$\n",
        "    \n",
        "    * In all the above layers we will be using the padding=\"same\" and stride=(1,1)\n",
        "    \n",
        "    * so that we can have the input and output matrices of same size\n",
        "    \n",
        "* <font color=\"red\">Example</font>:\n",
        "    * Assume the matrix shape of the input is (128,128,32) then the output it will be (128,128,32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RStu3wwZ0bBs",
        "colab_type": "text"
      },
      "source": [
        "*     <img src='https://i.imgur.com/prH3Mno.png' width=\"600\">\n",
        "* as shown in the architecture, after we get the AGCN it will get concatinated with the FSM output\n",
        "\n",
        "* If we observe the shapes both AGCN and FSM will have same height and weight\n",
        "\n",
        "* we will be concatinating both these outputs over the last axis\n",
        "\n",
        "* The concatinated output will be passed to a conv layers with filters = number of classes in our data set and the activation function = 'relu'\n",
        "\n",
        "* we will be using padding=\"same\" which results in the same size feature map\n",
        "\n",
        "* If you observe the shape of matrix, it will be 4x times less than the original image\n",
        "\n",
        "* to make it equal to the original output shape, we will do 4x times upsampling of rows and columns\n",
        "\n",
        "* apply <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling2D\">upsampling</a> with bilinear pooling as interpolation technique\n",
        "\n",
        "* Finally we will be applying sigmoid activation.\n",
        "\n",
        "* Example:\n",
        "    * Assume the matrix shape of AGCN is (128,128,32)  and FSM is (128,128,32) the concatination will make it (128, 128, 64)\n",
        "    * Applying conv layer will make it (128,128,21)\n",
        "    * Finally applying upsampling will make it (512, 512, 21)\n",
        "    * Applying sigmoid will result in the same matrix (512, 512, 21)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTOD_qPA0bBv",
        "colab_type": "text"
      },
      "source": [
        "* If you observe the arcitecture we are creating a feature map with 2x time less width and height\n",
        "* we have written the first stage of the code above.\n",
        "* Write the next layers by using the custom layers we have written"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9Cmyohz0bBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model, to_file='model4.png', show_shapes=True, show_layer_names=True,\n",
        "    rankdir='TB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXnPVQHw0bB1",
        "colab_type": "text"
      },
      "source": [
        "### Usefull tips:\n",
        "* use \"interpolation=cv2.INTER_NEAREST\" when you are resizing the image, so that it won't mess with the number of classes\n",
        "* keep the images in the square shape like $256*256$ or $512*512$\n",
        "* Carefull when you are converting the (W, H) output image into (W, H, Classes)\n",
        "* Even for the canet, use the segmentation model's losses and the metrics\n",
        "* The goal of this assignment is make you familier in with computer vision problems, image preprocessing, building complex architectures and implementing research papers, so that in future you will be very confident in industry\n",
        "* you can use the tensorboard logss to see how is yours model's training happening\n",
        "* use callbacks that you have implemented in previous assignments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHWYBsLz3pRY",
        "colab_type": "text"
      },
      "source": [
        "### Things to keep in mind"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fr7X4N0v1KlO",
        "colab_type": "text"
      },
      "source": [
        "* You need to train  above built model and plot the train and test losses.\n",
        "* Make sure there is no overfitting, you are free play with the identity blocks in C1, C2, C3, C4\n",
        "* before we apply the final sigmoid activation, you can add more conv layers or BN or dropouts etc\n",
        "* you are free to use any other optimizer or learning rate or weights init or regularizations"
      ]
    }
  ]
}